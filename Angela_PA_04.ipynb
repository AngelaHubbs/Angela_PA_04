{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940d65bc-011d-4762-8f7c-d628f2a81bcd",
   "metadata": {},
   "source": [
    "# Programming Assignment #4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ccdfcc-83fa-4eb2-a3b7-9671f72157e8",
   "metadata": {},
   "source": [
    "## Association rule mining \n",
    "\n",
    "The market basket transactions dataset (transactions_data.txt)contains list of items purchased by customer in each transaction.\n",
    "\n",
    "- load the transaction dataset file\n",
    "- use minimum support = 0.2 and use_colname=True in apriori method \n",
    "- select metric as confidence in association rules\n",
    "- use minimum threshold = 0.5\n",
    "\n",
    "Ex: If the minimum support is 0.4, the metric is confidence and minimum threshold is 0.5 then some of the outputs are: \n",
    "- the least frequency of frequent 1-itemset is ['Queso'].\n",
    "- the support, confidence, and lift of rule, ['Queso'] -> ['Tortilla chips'] are:\n",
    "  - consequent support = 0.7\n",
    "  - support = 0.4\n",
    "  - confidence = 1.00\n",
    "  - lift = 1.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52a75bcc-0ecd-48b3-9f20-43192869e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (2.1.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.6.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (3.10.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Downloading mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef59b37-5429-42b9-a45c-56ad45a7968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caeaf8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Lime', 'Queso', 'Salsa', 'Salt', 'Tortilla chips'],\n",
       " ['Ranch dip', 'Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Tortilla chips'],\n",
       " ['Potato chips', 'Ranch dip'],\n",
       " ['Salsa', 'Tortilla chips'],\n",
       " ['Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Ranch dip'],\n",
       " ['Guacamole', 'Tortilla chips'],\n",
       " ['Guacamole', 'Queso', 'Salsa', 'Tortilla chips'],\n",
       " ['Pita chips', 'Salsa']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the transactions dataset \n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Loading the data\n",
    "def load_dataset(path_to_data):\n",
    "    transactions = []\n",
    "    with open(path_to_data, 'r') as fid:\n",
    "        for lines in fid:\n",
    "            transaction = lines.strip().split(',')\n",
    "            transactions.append(transaction)\n",
    "    return transactions\n",
    "\n",
    "path_to_data = \"transactions_data.txt\"  \n",
    "dataset = load_dataset(path_to_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4cadf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support                        itemsets\n",
      "0       0.2                     (Guacamole)\n",
      "1       0.2                    (Pita chips)\n",
      "2       0.4                         (Queso)\n",
      "3       0.3                     (Ranch dip)\n",
      "4       0.6                         (Salsa)\n",
      "5       0.7                (Tortilla chips)\n",
      "6       0.2     (Guacamole, Tortilla chips)\n",
      "7       0.3                  (Salsa, Queso)\n",
      "8       0.4         (Tortilla chips, Queso)\n",
      "9       0.5         (Salsa, Tortilla chips)\n",
      "10      0.3  (Salsa, Tortilla chips, Queso)\n",
      "\n",
      "Association Rules:\n",
      "                antecedents              consequents  antecedent support  \\\n",
      "0               (Guacamole)         (Tortilla chips)                 0.2   \n",
      "1                   (Salsa)                  (Queso)                 0.6   \n",
      "2                   (Queso)                  (Salsa)                 0.4   \n",
      "3          (Tortilla chips)                  (Queso)                 0.7   \n",
      "4                   (Queso)         (Tortilla chips)                 0.4   \n",
      "5                   (Salsa)         (Tortilla chips)                 0.6   \n",
      "6          (Tortilla chips)                  (Salsa)                 0.7   \n",
      "7   (Salsa, Tortilla chips)                  (Queso)                 0.5   \n",
      "8            (Salsa, Queso)         (Tortilla chips)                 0.3   \n",
      "9   (Tortilla chips, Queso)                  (Salsa)                 0.4   \n",
      "10                  (Salsa)  (Tortilla chips, Queso)                 0.6   \n",
      "11                  (Queso)  (Salsa, Tortilla chips)                 0.4   \n",
      "\n",
      "    consequent support  support  confidence      lift  representativity  \\\n",
      "0                  0.7      0.2    1.000000  1.428571               1.0   \n",
      "1                  0.4      0.3    0.500000  1.250000               1.0   \n",
      "2                  0.6      0.3    0.750000  1.250000               1.0   \n",
      "3                  0.4      0.4    0.571429  1.428571               1.0   \n",
      "4                  0.7      0.4    1.000000  1.428571               1.0   \n",
      "5                  0.7      0.5    0.833333  1.190476               1.0   \n",
      "6                  0.6      0.5    0.714286  1.190476               1.0   \n",
      "7                  0.4      0.3    0.600000  1.500000               1.0   \n",
      "8                  0.7      0.3    1.000000  1.428571               1.0   \n",
      "9                  0.6      0.3    0.750000  1.250000               1.0   \n",
      "10                 0.4      0.3    0.500000  1.250000               1.0   \n",
      "11                 0.5      0.3    0.750000  1.500000               1.0   \n",
      "\n",
      "    leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0       0.06         inf       0.375000  0.285714   1.000000    0.642857  \n",
      "1       0.06         1.2       0.500000  0.428571   0.166667    0.625000  \n",
      "2       0.06         1.6       0.333333  0.428571   0.375000    0.625000  \n",
      "3       0.12         1.4       1.000000  0.571429   0.285714    0.785714  \n",
      "4       0.12         inf       0.500000  0.571429   1.000000    0.785714  \n",
      "5       0.08         1.8       0.400000  0.625000   0.444444    0.773810  \n",
      "6       0.08         1.4       0.533333  0.625000   0.285714    0.773810  \n",
      "7       0.10         1.5       0.666667  0.500000   0.333333    0.675000  \n",
      "8       0.09         inf       0.428571  0.428571   1.000000    0.714286  \n",
      "9       0.06         1.6       0.333333  0.428571   0.375000    0.625000  \n",
      "10      0.06         1.2       0.500000  0.428571   0.166667    0.625000  \n",
      "11      0.10         2.0       0.555556  0.500000   0.500000    0.675000  \n"
     ]
    }
   ],
   "source": [
    "# Transform the data to a format suitable for the apriori function\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the apriori algorithm\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)  \n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81071e13-02cb-40f2-8210-5e420bf572ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The least frequency of frequent 1-itemset is ['Guacamole']\n",
      "\n",
      "The support, confidence, and lift of rule, ['Guacamole'] -> ['Tortilla chips'] are:\n",
      "  • consequent support = 0.7\n",
      "  • support = 0.2\n",
      "  • confidence = 1.00\n",
      "  • lift = 1.43\n"
     ]
    }
   ],
   "source": [
    "# Find least frequent 1-itemset\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "itemsets_1 = frequent_itemsets[frequent_itemsets['length'] == 1].copy()\n",
    "itemsets_1_sorted = itemsets_1.sort_values('support')\n",
    "least_frequent = itemsets_1_sorted.iloc[0]\n",
    "least_frequent_item = list(least_frequent['itemsets'])[0]\n",
    "\n",
    "print(f\"\\nThe least frequency of frequent 1-itemset is ['{least_frequent_item}']\")\n",
    "\n",
    "# Find specific rule metrics\n",
    "for idx, rule in rules.iterrows():\n",
    "    antecedent_list = list(rule['antecedents'])\n",
    "    consequent_list = list(rule['consequents'])\n",
    "    \n",
    "    if antecedent_list == [least_frequent_item] and consequent_list == ['Tortilla chips']:\n",
    "        print(f\"\\nThe support, confidence, and lift of rule, ['{least_frequent_item}'] -> ['Tortilla chips'] are:\")\n",
    "        print(f\"  • consequent support = {rule['consequent support']:.1f}\")\n",
    "        print(f\"  • support = {rule['support']:.1f}\")\n",
    "        print(f\"  • confidence = {rule['confidence']:.2f}\")\n",
    "        print(f\"  • lift = {rule['lift']:.2f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0710ac-013c-460d-a373-eeb353299a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
